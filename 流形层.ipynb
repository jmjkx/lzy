{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 14 12:16:11 2019\n",
    "\n",
    "@author: viryl\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from ipdb import set_trace\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset as BaseDataset\n",
    "\n",
    "\n",
    "# 加载输入\n",
    "\n",
    "class MyDataset(BaseDataset):\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline\n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing\n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images_npy,\n",
    "            label_npy,\n",
    "\n",
    "           \n",
    "    ):\n",
    "\n",
    "\n",
    "        self.images = images_npy\n",
    "        self.labels = label_npy\n",
    "        self.length = images_npy.shape[0]\n",
    "        # convert str names to class values on masks\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "#a= MyDataset(img, label), a[0]\n",
    "        # read data\n",
    "        image = self.images[i]\n",
    "\n",
    "        label =  self.labels[i]\n",
    "\n",
    "         \n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        return torch.from_numpy(image), torch.from_numpy(np.array(label))\n",
    "        \n",
    "           \n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "# 返回一个patch 和label, a= MyDataset(img, label), len(a)\n",
    "\n",
    "\n",
    "  \n",
    "    # 包含patch image和相应label的元组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipdb import set_trace\n",
    "\n",
    "\n",
    "\n",
    "def validate(net, data_loader, set_name, classes_name):\n",
    "    \"\"\"\n",
    "    对一批数据进行预测，返回混淆矩阵以及Accuracy\n",
    "    :param net:\n",
    "    :param data_loader:\n",
    "    :param set_name:  eg: 'valid' 'train' 'tesst\n",
    "    :param classes_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    cls_num = len(classes_name)\n",
    "    conf_mat = np.zeros([cls_num, cls_num])\n",
    "\n",
    "    for data in data_loader:\n",
    "        images, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = net(images)\n",
    "        outputs.detach_()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 统计混淆矩阵\n",
    "        for i in range(len(labels)):\n",
    "            cate_i = labels[i]\n",
    "            pre_i = predicted[i]\n",
    "            conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "    for i in range(cls_num):\n",
    "        print('class:{:<10}, total num:{:<6}, correct num:{:<5}  Recall: {:.2%} Precision: {:.2%}'.format(\n",
    "            classes_name[i], np.sum(\n",
    "                conf_mat[i, :]), conf_mat[i, i], conf_mat[i, i] / (1 + np.sum(conf_mat[i, :])),\n",
    "            conf_mat[i, i] / (1 + np.sum(conf_mat[:, i]))))\n",
    "\n",
    "    print('{} set Accuracy:{:.2%}'.format(\n",
    "        set_name, np.trace(conf_mat) / np.sum(conf_mat)))\n",
    "\n",
    "    return conf_mat, '{:.2}'.format(np.trace(conf_mat) / np.sum(conf_mat))\n",
    "\n",
    "\n",
    "# 生成图像\n",
    "def show_confMat(confusion_mat, classes, set_name, out_dir):\n",
    "\n",
    "    # 归一化\n",
    "    confusion_mat_N = confusion_mat.copy()\n",
    "    for i in range(len(classes)):\n",
    "        confusion_mat_N[i, :] = confusion_mat[i, :] / confusion_mat[i, :].sum()\n",
    "\n",
    "    # 获取颜色\n",
    "    # 更多颜色: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    cmap = plt.cm.get_cmap('Greys')\n",
    "    plt.imshow(confusion_mat_N, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 设置文字\n",
    "    xlocations = np.array(range(len(classes)))\n",
    "    plt.xticks(xlocations, list(classes), rotation=60)\n",
    "    plt.yticks(xlocations, list(classes))\n",
    "    plt.xlabel('Predict label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion_Matrix_' + set_name)\n",
    "\n",
    "    # 打印数字\n",
    "    for i in range(confusion_mat_N.shape[0]):\n",
    "        for j in range(confusion_mat_N.shape[1]):\n",
    "            plt.text(x=j, y=i, s=int(\n",
    "                confusion_mat[i, j]), va='center', ha='center', color='red', fontsize=10)\n",
    "    # 保存\n",
    "    plt.savefig(os.path.join(out_dir, 'Confusion_Matrix' + set_name + '.png'))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ManifoldLayer(object):\n",
    "    def __init__(self, ReductionMethod):\n",
    "        self.ReductionMethod = ReductionMethod\n",
    "        \n",
    "        \n",
    "    def __call__(self, x, *arg, train = False):\n",
    "        _x = x.cpu().clone().detach().numpy()\n",
    "        \n",
    "        _x = _x.reshape(_x.shape[0]*_x.shape[1], _x.shape[2]*_x.shape[3])\n",
    "        if train:    \n",
    "            \n",
    "            self.M = self.ReductionMethod(_x, *arg)\n",
    "            self.M = np.array(self.M)\n",
    "            \n",
    "        \n",
    "        __x = np.dot(_x, self.M)\n",
    "        __x  = __x.reshape(x.shape[0], int(__x.shape[0] / x.shape[0]), int(sqrt(__x.shape[1])) , int(sqrt(__x.shape[1])))\n",
    "        return torch.from_numpy(__x).cuda()\n",
    "#         x = torch.tensor(x)\n",
    "#         x = torch.matmul(x.reshape(6000, 576), m1.T)\n",
    "    \n",
    "  \n",
    "     \n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transplant\n",
    "matlab = transplant.Matlab()\n",
    "def myMFA(channel,dim, kw, kb):\n",
    "    def calMatrix(x,y):\n",
    "        y = [np.argmax(one_hot)for one_hot in y]\n",
    "        y = np.array(y).reshape(len(y), 1)\n",
    "        \n",
    "       \n",
    "        return matlab.MFA(x.astype(np.double), y.astype(np.double), channel,dim, kw, kb)\n",
    "    return calMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def myPCA(dim):\n",
    "    def calMatrix(X):\n",
    "        pca.fit(X)\n",
    "        M = pca.components_\n",
    "        return M.T\n",
    "    pca = PCA(n_components=dim, svd_solver = 'auto')    \n",
    "    return calMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from ipdb import set_trace\n",
    "from math import sqrt       \n",
    "     \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5).double() \n",
    "        self.fc1   = nn.Linear(256,128)  \n",
    "        self.fc2   = nn.Linear(128, 10)\n",
    "#         self.manifold1 = ManifoldLayer(myMFA(6, 256, 5, 10))\n",
    "#         self.manifold2 = ManifoldLayer(myMFA(16, 16, 5, 10))   \n",
    "        self.manifold1 = ManifoldLayer(myPCA(256))\n",
    "        self.manifold2 = ManifoldLayer(myPCA(16))  \n",
    "\n",
    "    def forward(self, x, *y, train=False): \n",
    "        self.batchsize = x.shape[0]\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "      #  ============================\n",
    "        x = self.manifold1(x, *y, train=train)\n",
    "       \n",
    "       # =================================\n",
    "       \n",
    "        x = self.conv2(x)\n",
    "    #    ===================================\n",
    "        x = self.manifold2(x, *y, train=train)\n",
    "        \n",
    "\n",
    "       # ===================================\n",
    "        x = x.view(x.size()[0], -1)   #展开成一维的\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "import sklearn\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import numpy\n",
    "import gzip\n",
    "\n",
    "\n",
    "# Params for MNIST\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "# Extract the images\n",
    "def extract_data(filename, num_images):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "        data = numpy.reshape(data, [num_images, -1])\n",
    "    return data\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    print('Extracting', filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "        num_labels_data = len(labels)\n",
    "        one_hot_encoding = numpy.zeros((num_labels_data,NUM_LABELS))\n",
    "        one_hot_encoding[numpy.arange(num_labels_data),labels] = 1\n",
    "        one_hot_encoding = numpy.reshape(one_hot_encoding, [-1, NUM_LABELS])\n",
    "    return one_hot_encoding\n",
    "x_train = extract_data(r'F:\\lzy\\data\\mnist/train-images-idx3-ubyte.gz', 60000)\n",
    "y_train = extract_labels(r'F:\\lzy\\data\\mnist/train-labels-idx1-ubyte.gz', 60000)\n",
    "x_test = extract_data(r'F:\\lzy\\data\\mnist/t10k-images-idx3-ubyte.gz', 10000)\n",
    "y_test = extract_labels(r'F:\\lzy\\data\\mnist/t10k-labels-idx1-ubyte.gz', 10000)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 100\n",
    "classes_name = [str(c) for c in range(10)]  # 分类地物数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 1, 28, 28)\n",
    "x_test = x_test.reshape(10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Epoch[001/1000] Iteration[600/600] Loss: 1321.8424 Acc:10.44%\n",
      "Valid set Accuracy:10.28%\n",
      "Training: Epoch[002/1000] Iteration[600/600] Loss: 1303.5724 Acc:14.18%\n",
      "Valid set Accuracy:14.19%\n",
      "Training: Epoch[003/1000] Iteration[600/600] Loss: 1300.1789 Acc:25.71%\n",
      "Valid set Accuracy:25.89%\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorboardX import  SummaryWriter\n",
    "\n",
    "training_dataset = MyDataset(x_train, y_train)\n",
    "testing_dataset = MyDataset(x_test, y_test)\n",
    "# Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=testing_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 检查cuda是否可用\n",
    "\n",
    "# 生成log\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "log_path = os.path.join(os.getcwd(), \"log\")\n",
    "log_dir = os.path.join(log_path, time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------搭建网络--------------------------\n",
    "cnn = Net()  # 创建CNN, 输入全连接层维数\n",
    "\n",
    "cnn = cnn.double()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------------设置损失函数和优化器----------------------\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)  # lr:(default: 1e-3)优化器\n",
    "criterion = nn.CrossEntropyLoss()  # 损失函数\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=EPOCH/2, gamma=0.5)  # 设置学习率下降策略\n",
    "\n",
    "# --------------------训练------------------------------\n",
    " # 使用GPU\n",
    "cnn = cnn.cuda()\n",
    "for epoch in range(EPOCH):\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.double()\n",
    "        labels = labels.double()\n",
    "        \n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        cnn = cnn.train()\n",
    "        label_numpy = labels.cpu().numpy()\n",
    "        \n",
    "#         outputs = cnn(inputs,  label_numpy , train=True)\n",
    "        outputs = cnn(inputs, train=True)\n",
    "        loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "     \n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权值\n",
    "        loss_sigma += loss.item()\n",
    "        # 统计预测信息\n",
    "    final_outputs = cnn(torch.from_numpy(x_train).double().cuda(), train=False)\n",
    "    final_outputs.detach_() \n",
    "    _, predicted = torch.max(final_outputs, 1)\n",
    "    \n",
    "    total = y_train.shape[0]\n",
    "   \n",
    "    correct = ((predicted ==  torch.max(torch.from_numpy(y_train).cuda(), 1)[1]).squeeze().sum()).item()\n",
    "    \n",
    "\n",
    "        # 每 BATCH_SIZE 个 iteration 打印一次训练信息，loss为 BATCH_SIZE 个 iteration 的平均   \n",
    "    loss_avg = loss_sigma / BATCH_SIZE\n",
    "    \n",
    "    print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "        epoch + 1, EPOCH, batch_idx + 1, len(train_loader), loss_sigma, correct / total))\n",
    "    # 记录训练loss\n",
    "    writer.add_scalars(\n",
    "        'Loss_group', {'train_loss': loss_avg}, epoch)\n",
    "    # 记录learning rate\n",
    "    writer.add_scalar(\n",
    "        'learning rate', scheduler.get_lr()[0], epoch)\n",
    "    # 记录Accuracy\n",
    "    writer.add_scalars('Accuracy_group', {\n",
    "                       'train_acc': correct / total}, epoch)\n",
    "    # 每个epoch，记录梯度，权值\n",
    "#     for name, layer in cnn.named_parameters():\n",
    "#         writer.add_histogram(\n",
    "#             name + '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "#         writer.add_histogram(name + '_data', layer.cpu().data.numpy(), epoch)\n",
    "\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    if epoch % 1 == 0:\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = len(classes_name)\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        cnn.eval()\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            images, labels = data\n",
    "             \n",
    "            \n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            images = images.double()\n",
    "            labels = labels.double()\n",
    "            cnn.cuda()\n",
    "            cnn = cnn.train()\n",
    "            \n",
    "            outputs = cnn(images)  # forward\n",
    "           \n",
    "            outputs.detach_()  # 不求梯度\n",
    "            \n",
    "            loss = criterion(outputs, torch.max(labels, 1)[1])  # 计算loss\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)  # 统计\n",
    "            # labels = labels.data    # Variable --> tensor\n",
    "            # 统计混淆矩阵\n",
    "            for j in range(len(labels)):\n",
    "                \n",
    "                \n",
    "                cate_i =  torch.max(labels, 1)[1][j]\n",
    "                pre_i =  predicted[j]\n",
    "                conf_mat[int(cate_i), int(pre_i)] += 1.0\n",
    "        print('{} set Accuracy:{:.2%}'.format(\n",
    "            'Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "        # 记录Loss, accuracy\n",
    "        writer.add_scalars(\n",
    "            'Loss_group', {'valid_loss': loss_sigma / len(test_loader)}, epoch)\n",
    "        writer.add_scalars('Accuracy_group', {\n",
    "                           'valid_acc': conf_mat.trace() / conf_mat.sum()}, epoch)\n",
    "print('Finished Training')\n",
    "\n",
    "# ----------------------- 保存模型 并且绘制混淆矩阵图 -------------------------\n",
    "cnn_save_path = os.path.join(log_dir, 'net_params.pkl')\n",
    "torch.save(cnn.state_dict(), cnn_save_path)\n",
    "\n",
    "conf_mat_train, train_acc = F(cnn, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(cnn, test_loader, 'test', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
